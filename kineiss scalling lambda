AWSTemplateFormatVersion: '2010-09-09'
Description: |
  CloudFormation template for auto?scaling a Kinesis Data Stream based solely on the GetRecords.Latency metric (in milliseconds). Scaling logic:
    - If latency < 200 ms ? 1 shard
    - If 200 ms ? latency < 400 ms ? 2 shards
    - If 400 ms ? latency < 600 ms ? 4 shards
    - If 600 ms ? latency < 800 ms ? 6 shards
    - If 800 ms ? latency < 1000 ms ? 8 shards
    - If latency ? 1000 ms ? 10 shards
  A cooldown period of 5 minutes is enforced between scaling actions.

Parameters:
  StreamName:
    Type: String
    Default: MyDataStream
    Description: Name of the Kinesis Data Stream to auto-scale.

Resources:
  ##########################################
  # Kinesis Data Stream
  ##########################################
  DataStream:
    Type: AWS::Kinesis::Stream
    Properties:
      Name: !Ref StreamName
      ShardCount: 1

  ##########################################
  # SNS Topic for scaling notifications
  ##########################################
  ScalingTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: !Sub ${StreamName}-Scaling-Alerts
      TopicName: !Sub ${StreamName}-Scaling-Topic

  ##########################################
  # IAM Role for the Lambda function
  ##########################################
  ScalingFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${StreamName}-ScalingLambdaRole
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: KinesisScalingPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - kinesis:DescribeStreamSummary
                  - kinesis:UpdateShardCount
                Resource: !Sub arn:aws:kinesis:${AWS::Region}:${AWS::AccountId}:stream/${StreamName}

  ##########################################
  # Lambda Function for Scaling
  ##########################################
  ScalingFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub ${StreamName}-ScalingHandler
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt ScalingFunctionRole.Arn
      Timeout: 60
      MemorySize: 256
      Environment:
        Variables:
          STREAM_NAME: !Ref StreamName
          COOLDOWN_SECONDS: '300' # 5 minutes cooldown
      Code:
        ZipFile: |
          import os
          import json
          import time
          import logging
          from datetime import datetime, timedelta
          import boto3
          from botocore.exceptions import ClientError

          # Configure enhanced logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          # Initialize AWS SDK clients
          kinesis_client = boto3.client('kinesis')
          cloudwatch_client = boto3.client('cloudwatch')

          # In-memory cooldown tracking (persists only in warm Lambda instances)
          last_scale_times = {}  # { stream_name: timestamp }

          def parse_alarm_event(event):
              """
              Parse the SNS alarm event sent from CloudWatch.
              Returns a dict with keys: AlarmName, NewStateValue, and NewStateReason.
              """
              try:
                  sns_record = event['Records'][0]['Sns']
                  message = sns_record.get('Message', '{}')
                  alarm_event = json.loads(message)
                  return {
                      'AlarmName': alarm_event.get('AlarmName', 'UnknownAlarm'),
                      'NewStateValue': alarm_event.get('NewStateValue', 'UNKNOWN'),
                      'NewStateReason': alarm_event.get('NewStateReason', '')
                  }
              except Exception as e:
                  logger.error(f"Error parsing alarm event: {e}", exc_info=True)
                  raise

          def enforce_cooldown(cooldown_seconds, stream_name):
              """
              Enforce a cooldown period between scaling actions.
              Returns True if scaling should be skipped.
              """
              now = time.time()
              last_time = last_scale_times.get(stream_name)
              if last_time is not None and (now - last_time) < cooldown_seconds:
                  logger.info(f"Cooldown active for stream {stream_name}: last scaled {now - last_time:.0f}s ago (waiting {cooldown_seconds}s).")
                  return True
              return False

          def get_current_shard_count(stream_name):
              """
              Retrieve the current shard count for the Kinesis stream.
              """
              try:
                  response = kinesis_client.describe_stream_summary(StreamName=stream_name)
                  shard_count = response['StreamDescriptionSummary']['OpenShardCount']
                  logger.info(f"Current shard count for stream {stream_name}: {shard_count}")
                  return shard_count
              except ClientError as e:
                  logger.error(f"Error describing stream {stream_name}: {e}", exc_info=True)
                  raise

          def get_latest_latency(stream_name):
              """
              Retrieve the average GetRecords.Latency for the past 5 minutes.
              Note: The metric is in milliseconds.
              """
              try:
                  end_time = datetime.utcnow()
                  start_time = end_time - timedelta(minutes=5)
                  response = cloudwatch_client.get_metric_statistics(
                      Namespace='AWS/Kinesis',
                      MetricName='GetRecords.Latency',
                      Dimensions=[{'Name': 'StreamName', 'Value': stream_name}],
                      StartTime=start_time,
                      EndTime=end_time,
                      Period=300,          # 5 minutes period
                      Statistics=['Average']
                  )
                  datapoints = response.get('Datapoints', [])
                  if not datapoints:
                      logger.warning(f"No latency datapoints available for stream {stream_name}.")
                      return None
                  latest_dp = sorted(datapoints, key=lambda x: x['Timestamp'])[-1]
                  latency_ms = latest_dp['Average']  # Already in milliseconds
                  logger.info(f"Latest average latency for stream {stream_name}: {latency_ms:.0f} ms")
                  return latency_ms
              except ClientError as e:
                  logger.error(f"Error fetching latency for stream {stream_name}: {e}", exc_info=True)
                  raise

          def decide_desired_shard_count(latency_ms):
              """
              Determine the target shard count based on measured latency in ms:
                - If latency < 200 ms ? 1 shard
                - 200 ms ? latency < 400 ms ? 2 shards
                - 400 ms ? latency < 600 ms ? 4 shards
                - 600 ms ? latency < 800 ms ? 6 shards
                - 800 ms ? latency < 1000 ms ? 8 shards
                - Latency ? 1000 ms ? 10 shards
              """
              logger.info(f"Using measured latency: {latency_ms:.0f} ms")
              if latency_ms < 200:
                  return 1
              elif 200 <= latency_ms < 400:
                  return 2
              elif 400 <= latency_ms < 600:
                  return 4
              elif 600 <= latency_ms < 800:
                  return 6
              elif 800 <= latency_ms < 1000:
                  return 8
              else:
                  return 10

          def update_stream_shard_count(stream_name, target_shards):
              """
              Call the Kinesis API to update the shard count for the stream.
              """
              try:
                  logger.info(f"Updating stream {stream_name} to {target_shards} shards.")
                  kinesis_client.update_shard_count(
                      StreamName=stream_name,
                      TargetShardCount=target_shards,
                      ScalingType='UNIFORM_SCALING'
                  )
                  logger.info(f"Stream {stream_name} successfully updated to {target_shards} shards.")
              except ClientError as e:
                  logger.error(f"Error updating shard count for stream {stream_name}: {e}", exc_info=True)
                  raise

          def lambda_handler(event, context):
              try:
                  logger.info("Lambda invoked with event: " + json.dumps(event))
                  # Parse the incoming alarm event from SNS
                  alarm_data = parse_alarm_event(event)
                  alarm_name = alarm_data.get('AlarmName')
                  new_state = alarm_data.get('NewStateValue')
                  logger.info(f"Alarm '{alarm_name}' transitioned to state: {new_state}")

                  # Process only if alarm state is ALARM
                  if new_state != "ALARM":
                      logger.info("Alarm state is not ALARM. Exiting without scaling action.")
                      return

                  stream_name = os.environ.get('STREAM_NAME')
                  if not stream_name:
                      logger.error("STREAM_NAME environment variable is not set.")
                      return

                  cooldown_seconds = int(os.environ.get('COOLDOWN_SECONDS', '300'))
                  if enforce_cooldown(cooldown_seconds, stream_name):
                      logger.info("Cooldown period active. Skipping scaling action.")
                      return

                  current_shards = get_current_shard_count(stream_name)
                  latency_ms = get_latest_latency(stream_name)
                  if latency_ms is None:
                      logger.error("Unable to retrieve latency metric. Exiting scaling function.")
                      return

                  desired_shards = decide_desired_shard_count(latency_ms)
                  logger.info(f"Based on latency, desired shard count is {desired_shards}.")

                  if current_shards == desired_shards:
                      logger.info("Current shard count equals desired count. No scaling required.")
                      return

                  update_stream_shard_count(stream_name, desired_shards)
                  # Record scaling action time for cooldown enforcement
                  last_scale_times[stream_name] = time.time()
              except Exception as e:
                  logger.error(f"Unhandled exception in lambda_handler: {e}", exc_info=True)
                  raise

  ##########################################
  # SNS Subscription for the Lambda function
  ##########################################
  ScalingSubscription:
    Type: AWS::SNS::Subscription
    Properties:
      TopicArn: !Ref ScalingTopic
      Protocol: lambda
      Endpoint: !GetAtt ScalingFunction.Arn

  ##########################################
  # Lambda Permission for SNS to invoke the function
  ##########################################
  ScalingFunctionInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref ScalingFunction
      Action: lambda:InvokeFunction
      Principal: sns.amazonaws.com
      SourceArn: !Ref ScalingTopic

  ##########################################
  # CloudWatch Alarm for High Latency (Scale-Up Trigger)
  ##########################################
  AlarmHighLatency:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${StreamName}-HighLatency
      AlarmDescription: Triggers when GetRecords.Latency > 200 ms (scale-up trigger)
      Namespace: AWS/Kinesis
      MetricName: GetRecords.Latency
      Dimensions:
        - Name: StreamName
          Value: !Ref StreamName
      Statistic: Average
      Period: 300 # 5 minutes per datapoint
      EvaluationPeriods: 3 # Require 3 consecutive datapoints (15 minutes total)
      Threshold: 200 # in milliseconds
      ComparisonOperator: GreaterThanThreshold
      AlarmActions:
        - !Ref ScalingTopic

  ##########################################
  # CloudWatch Alarm for Low Latency (Scale-Down Trigger)
  ##########################################
  AlarmLowLatency:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${StreamName}-LowLatency
      AlarmDescription: Triggers when GetRecords.Latency < 200 ms (scale-down trigger)
      Namespace: AWS/Kinesis
      MetricName: GetRecords.Latency
      Dimensions:
        - Name: StreamName
          Value: !Ref StreamName
      Statistic: Average
      Period: 300 # 5 minutes per datapoint
      EvaluationPeriods: 5 # Require 5 consecutive datapoints (25 minutes total)
      Threshold: 200 # in milliseconds
      ComparisonOperator: LessThanThreshold
      AlarmActions:
        - !Ref ScalingTopic

Outputs:
  KinesisStreamName:
    Description: Name of the Kinesis Data Stream
    Value: !Ref DataStream
  ScalingLambdaFunction:
    Description: Lambda function for auto-scaling the Kinesis stream
    Value: !Ref ScalingFunction
  ScalingSNSTopic:
    Description: SNS Topic for scaling notifications
    Value: !Ref ScalingTopic
